---
title: Эспертная оценка вин
output: html_document
---

Прочитаем данные и перемешаем на всякий случай строки в случайном порядке.
```{r}
wine <- read.table("wine.csv", sep=";", header=T, fileEncoding="UTF-8")
wine <- wine[sample.int(nrow(wine)),]
```

Вот так выглядит распределение экспертной оценки вин в выборке:
```{r}
barplot(table(wine$Экспертная.оценка) / nrow(wine), col="red", xlab="Экспертная оценка", ylab="Доля вин")
box()
```

Давайте научимся оценивать этот признак, чтобы мы могли заранее предположить, какую оценку получит како-то новое вино, которого в выборке нет.
Чтобы смоделировать такую ситуацию, отделим 25% выборки для контроля качества предсказания:
```{r, message=F}
library(caret)
inTrain <- createDataPartition(y = wine$Экспертная.оценка, p = 0.75, list = F)
```

Если у нас нет больше никакой информации о винах, то наше лучшее предположение об оценке — среднее имеющихся в обучающей выборке:
```{r}
mean(wine$Экспертная.оценка[inTrain])
```

Если мы будем предсказывать этой величиной оценку всех вин, на обучающей выборке мы получим качество 
```{r}
RMSE(rep(mean(wine$Экспертная.оценка[inTrain]), length(inTrain)), wine$Экспертная.оценка[inTrain])
```
а на тестовой
```{r}
RMSE(rep(mean(wine$Экспертная.оценка[inTrain]), nrow(wine)-length(inTrain)), wine$Экспертная.оценка[-inTrain])
```
На тестовой выборке ошибка больше, поскольку среднее мы оценивали по обучающей. Это естественный эффект.

### Тип вина
Какая-то ещё информация у нас есть, например, о типе вина:
```{r}
table(wine$Тип)
```

Распределения оценок по типам довольно сильно отличаются:
```{r, }
par(mfrow=c(1,2))
barplot(table(wine$Экспертная.оценка[wine$Тип == "красное"]) / sum(wine$Тип == "красное"), col="red", xlab="Экспертная оценка", ylab="Доля вин", main="Красные вина")
box()
barplot(table(wine$Экспертная.оценка[wine$Тип == "белое"]) / sum(wine$Тип == "белое"), col="white", xlab="Экспертная оценка", ylab="Доля вин", main="Белые вина")
box()
```

Различие между средними статистически значимо:
```{r}
t.test(wine$Экспертная.оценка[wine$Тип == "красное"], wine$Экспертная.оценка[wine$Тип == "белое"])
```

Чтобы уточнить наше предсказание, можно оценку каждого вина предсказывать средним по оценкам вин такого же типа в выборке:
```{r}
m0 <- train(Экспертная.оценка~Тип, method="lm", data=wine[inTrain,])
```

Ошибки предсказания немного уменьшились:
```{r}
RMSE(predict(m0, newdata=wine[inTrain,]), wine$Экспертная.оценка[inTrain])
RMSE(predict(m0, newdata=wine[-inTrain,]), wine$Экспертная.оценка[-inTrain])
```

Вот так выглядят истинные оценки вин и их предсказания средними по типам на тестовой выборке:
```{r}
plot(wine$Экспертная.оценка[inTrain], 
     predict(m0, newdata = wine[inTrain,]), 
     pch=20, col=rgb(255,0,0,50, maxColorValue = 255), xlim=c(3,9), ylim=c(3,9), xlab="Экспертная оценка", ylab="Оценка экспертной оценки")
grid()
lines(c(0,10), c(0,10), col="black")
```

### Другие признаки
На самом деле у нас есть ещё 11 признаков, описывающих химический состав вин:
```{r}
for (i in 2:(ncol(wine)-1)){
  plot(jitter(wine$Экспертная.оценка), wine[,i], ylab=gsub( "\\.", " ", gsub("г.", "г/", colnames(wine)[i])), xlab="Экспертная оценка", col="black", bg=c("white", "red")[wine$Тип], pch=21)
}
```

Попробуем их учесть при построении прогноза оценок. 

#### Линейная регрессия
Построим для начала линейную регрессионную модель.
```{r}
m1 <- train(Экспертная.оценка~., method="lm", data=wine[inTrain,])
```
Ошибки предсказания существенно уменьшились:
```{r}
RMSE(predict(m1, newdata=wine[inTrain,]), wine$Экспертная.оценка[inTrain])
RMSE(predict(m1, newdata=wine[-inTrain,]), wine$Экспертная.оценка[-inTrain])
```

Истинные оценки вин и их предсказания линейной моделью:
```{r}
plot(wine$Экспертная.оценка[inTrain], 
     predict(m1, newdata = wine[inTrain,]), 
     pch=20, col=rgb(255,0,0,50, maxColorValue = 255), xlim=c(3,9), ylim=c(3,9), xlab="Экспертная оценка", ylab="Оценка экспертной оценки", 
     main = "Обучающая выборка")
grid()
lines(c(0,10), c(0,10), col="black")

plot(wine$Экспертная.оценка[-inTrain], 
     predict(m1, newdata = wine[-inTrain,]), 
     pch=20, col=rgb(255,0,0,50, maxColorValue = 255), xlim=c(3,9), ylim=c(3,9), xlab="Экспертная оценка", ylab="Оценка экспертной оценки", 
     main = "Тестовая выборка")
grid()
lines(c(0,10), c(0,10), col="black")
```


#### Регуляризованный случайный лес
Построим  регуляризованный случайный лес.
```{r}
m3 <- train(Экспертная.оценка~., method="RRF", data=wine[inTrain,])
```

Его ошибка предсказания на тестовой выборке ещё меньше:
```{r}
RMSE(predict(m3, newdata=wine[inTrain,]), wine$Экспертная.оценка[inTrain])
RMSE(predict(m3, newdata=wine[-inTrain,]), wine$Экспертная.оценка[-inTrain])
```

Качество предсказаний на контрольной и тестовой выборках примерно одинаково:
```{r}
plot(wine$Экспертная.оценка[inTrain], 
     predict(m3, newdata = wine[inTrain,]), 
     pch=20, col=rgb(255,0,0,50, maxColorValue = 255), xlim=c(3,9), ylim=c(3,9), xlab="Экспертная оценка", ylab="Оценка экспертной оценки", 
     main = "Обучающая выборка")
grid()
lines(c(0,10), c(0,10), col="black")

plot(wine$Экспертная.оценка[-inTrain], 
     predict(m3, newdata = wine[-inTrain,]), 
     pch=20, col=rgb(255,0,0,50, maxColorValue = 255), xlim=c(3,9), ylim=c(3,9), xlab="Экспертная оценка", ylab="Оценка экспертной оценки", 
     main = "Тестовая выборка")
grid()
lines(c(0,10), c(0,10), col="black")
```

